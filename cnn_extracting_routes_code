# this code uses the code written in this repository & youtube video with a few minor adjustments 
# https://github.com/bnsreenu/python_for_image_processing_APEER/blob/master/tutorial118_binary_semantic_segmentation_using_unet.ipynb
# link to data https://drive.google.com/file/d/1Vbv60Bgnpe17VAWrCMWBUyALIsk2_-Jf/view?usp=share_link

# set up the environment
from tensorflow.keras.utils import normalize
import os
import cv2
from PIL import Image
import numpy as np
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import Adam
import glob
import random
from tensorflow.keras.metrics import MeanIoU



#set up image directories:
image_directory = 'image directories are defined here'
mask_directory = 'image directories are defined here'

# set the size (400 images available using fewer for now to save time)
SIZE = 250
num_images = 250

# processing the map images to make sure they're in the right shape, size, and ordered correctly
image_names = glob.glob("image directories are defined here/maps*.tif")
print(image_names)

image_names.sort()
print(image_names)

image_names_subset = image_names[0:num_images]
images = [cv2.imread(img) for img in image_names_subset]
image_dataset = np.array(images)
#image_dataset = (image_dataset > 0).astype(int)
image_dataset = np.expand_dims(image_dataset, axis = 3)

print("Max pixel value in image is: ", image_dataset.max())
print("Labels in the mask are : ", np.unique(image_dataset))

# define the masks that match the map images imported above 

mask_names = glob.glob("image directories are defined here/masks*.tif")
mask_names.sort()
mask_names_subset = mask_names[0:num_images]
masks = [cv2.imread(mask, -1) for mask in mask_names_subset]
mask_dataset = np.array(masks)
#mask_dataset = (mask_dataset > 0).astype(int)
mask_dataset = np.expand_dims(mask_dataset, axis = 3)

print("Max pixel value in image is: ", mask_dataset.max())
print("Labels in the mask are : ", np.unique(mask_dataset))


# Normalize images
image_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler
#Do not normalize masks, just rescale to 0 to 1.
mask_dataset = mask_dataset /255.  #PIxel values will be 0 or 1
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 42)

X_train = np.float32(X_train)
#X_train = (X_train > 0).astype(int)

X_test = np.float32(X_test)
#X_test = (X_test > 0).astype(int)

y_train = np.float32(y_train)
#y_train = (y_train > 0).astype(int)

y_test = np.float32(y_test)
#y_test = (y_test > 0).astype(int)


#Sanity check, view few mages

image_number = random.randint(0, len(X_train)-1)
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(X_train[image_number,:,:,0], cmap='gray')
plt.subplot(122)
plt.imshow(y_train[image_number,:,:,0], cmap='gray')
plt.show()

image_dataset = (image_dataset > 0).astype(int)
mask_dataset = (mask_dataset > 0).astype(int)


print("Image data shape is: ", image_dataset.shape)
print("Mask data shape is: ", mask_dataset.shape)
print("Max pixel value in image is: ", image_dataset.max())
print("Labels in the mask are : ", np.unique(mask_dataset))



# Building Unet by dividing encoder and decoder into blocks
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda
from keras.optimizers import Adam
from keras.layers import Activation, MaxPool2D, Concatenate


def conv_block(input, num_filters):
    x = Conv2D(num_filters, 3, padding="same")(input)
    x = BatchNormalization()(x)   #Not in the original network. 
    x = Activation("relu")(x)

    x = Conv2D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)  #Not in the original network
    x = Activation("relu")(x)

    return x


#Encoder block: Conv block followed by maxpooling


def encoder_block(input, num_filters):
    x = conv_block(input, num_filters)
    p = MaxPool2D((2, 2))(x)
    return x, p   

#Decoder block
#skip features gets input from encoder for concatenation

def decoder_block(input, skip_features, num_filters):
    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding="same")(input)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x

def decoder_block2(input, skip_features, num_filters):
    x = Conv2DTranspose(num_filters, (2, 2), strides=2, output_padding=(1,1))(input)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x

#Build Unet using the blocks
def build_unet(input_shape, n_classes):
    inputs = Input(input_shape)

    s1, p1 = encoder_block(inputs, 64)  
    print(s1.shape)
    print(p1.shape)

    s2, p2 = encoder_block(p1, 128)
    print(s2.shape)
    print(p2.shape)
    
    s3, p3 = encoder_block(p2, 256)
    print(s3.shape)
    print(p3.shape)
    s4, p4 = encoder_block(p3, 512)
    print(s4.shape)
    print(p4.shape)
    
    b1 = conv_block(p4, 1024) #Bridge
    print(b1.shape)

    d1 = decoder_block2(b1, s4, 512)
    print(d1.shape)
    print(p2.shape)
    d2 = decoder_block(d1, s3, 256)
    print(s2.shape)
    print(p2.shape)
    d3 = decoder_block2(d2, s2, 128)
    print(s2.shape)
    print(p2.shape)
    d4 = decoder_block(d3, s1, 64)
    print(s2.shape)
    print(p2.shape)



    outputs = Conv2D(n_classes, 1, padding="same")(d4)  #Change the activation based on n_classes
    #print(activation)

    model = Model(inputs, outputs, name="U-Net")
    return model


IMG_HEIGHT = image_dataset.shape[1]
IMG_WIDTH  = image_dataset.shape[2]
IMG_CHANNELS = image_dataset.shape[3]


# build the model 
input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)
model = build_unet(input_shape, n_classes=2)
model.compile(optimizer=Adam(learning_rate = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()


# run the model
history = model.fit(X_train, y_train, 
                    batch_size = 15, 
                    verbose=1, 
                    epochs= 5, 
                    validation_data=(X_test, y_test), 
                    shuffle=False)


#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
plt.plot(epochs, acc, 'y', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


#IOU
y_pred=model.predict(X_test)
y_pred_thresholded = y_pred > 0.5
     

     

n_classes = 2
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_pred_thresholded, y_test)
print("Mean IoU =", IOU_keras.result().numpy())
     


threshold = 0.5
test_img_number = random.randint(0, len(X_test)-1)
test_img = X_test[test_img_number]
ground_truth=y_test[test_img_number]
test_img_input=np.expand_dims(test_img, 0)
print(test_img_input.shape)
prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)
print(prediction.shape)

plt.figure(figsize=(16, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img[:,:,0], cmap='gray')
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth[:,:,0], cmap='gray')
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(prediction, cmap='gray')

plt.show()
